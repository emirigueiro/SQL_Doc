{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo .sql\n",
    "with open('Query_polizas_gs.sql', 'r', encoding='utf-8') as file:\n",
    "    sql_query = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[134], line 21\u001b[0m\n\u001b[0;32m     16\u001b[0m     list_documentation\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(coincidencia))\n\u001b[0;32m     18\u001b[0m df_documentation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocs_coments\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m  list_documentation\n\u001b[1;32m---> 21\u001b[0m \u001b[43mdf_documentation\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstep\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcoment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m df_documentation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocs_coments\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m, expand \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Llenar los valores NaN con una cadena vacía\u001b[39;00m\n\u001b[0;32m     25\u001b[0m df_documentation\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Boreal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4299\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_frame(key, value)\n\u001b[0;32m   4298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (Series, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m, Index)):\n\u001b[1;32m-> 4299\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4300\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m   4301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[1;32mc:\\Users\\Boreal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4341\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4337\u001b[0m     \u001b[38;5;66;03m# Note: unlike self.iloc[:, indexer] = value, this will\u001b[39;00m\n\u001b[0;32m   4338\u001b[0m     \u001b[38;5;66;03m#  never try to overwrite values inplace\u001b[39;00m\n\u001b[0;32m   4340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m-> 4341\u001b[0m         \u001b[43mcheck_key_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4342\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(key, value\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m   4343\u001b[0m             \u001b[38;5;28mself\u001b[39m[k1] \u001b[38;5;241m=\u001b[39m value[k2]\n",
      "File \u001b[1;32mc:\\Users\\Boreal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexers\\utils.py:390\u001b[0m, in \u001b[0;36mcheck_key_length\u001b[1;34m(columns, key, value)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(key):\n\u001b[1;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns must be same length as key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# Missing keys in columns are represented as -1\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(key)[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns):\n",
      "\u001b[1;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "# Define una expresión regular para encontrar todo lo que está entre '--' y '---'\n",
    "patron_1 = r'--Sumery:(.*?)-----------------------------------------------------------------------------------------------------------------------------'\n",
    "\n",
    "patron_2 = r'(Step|LC)(.*?)--'\n",
    "\n",
    "patron_3 = r'--(.*?)--'\n",
    "\n",
    "# Encuentra todas las coincidencias en el contenido del archivo\n",
    "coincidencias = re.findall(patron_2, sql_query, re.DOTALL)\n",
    "\n",
    "# Se guardar los comentarios en un df y en una lista. \n",
    "list_documentation = []\n",
    "df_documentation = pd.DataFrame ()\n",
    "\n",
    "for coincidencia in coincidencias:\n",
    "    list_documentation.append(str(coincidencia))\n",
    "\n",
    "df_documentation['docs_coments'] =  list_documentation\n",
    "\n",
    "\n",
    "df_documentation[['step','coment']] = df_documentation['docs_coments'].str.split(':', expand = True)\n",
    "\n",
    "\n",
    "# Llenar los valores NaN con una cadena vacía\n",
    "df_documentation.fillna('', inplace=True)\n",
    "\n",
    "# Limpieza de los comentarios en el DF.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         docs_coments\n",
      "0   ('Step', ' 1: Se obtienen todas las talta de H...\n",
      "1   ('LC', ': Se limitan las altas por id de estru...\n",
      "2   ('LC', ': Se limita el universo a la primera p...\n",
      "3   ('Step', ' 2: Proceso para obtener las altas d...\n",
      "4   ('Step', ' 2_1: Se genera una temporal con las...\n",
      "5   ('LC', ': Se limita el universo solo a las cam...\n",
      "6   ('LC', ': Trae solamente las gestiones de vent...\n",
      "7   ('Step', ' 2_2: Cruce con cotizaciones para ob...\n",
      "8   ('LC', ': Generarmo un flg para identifiar aqu...\n",
      "9   ('Step', ' 2_3: Se realiza el cruce con certif...\n",
      "10  ('LC', ': Generamos un flg para identifiar aqu...\n",
      "11  ('Step', ' 2_4: Se realiza un cruce con cotiza...\n",
      "12  ('LC', ': Generarmo un flg para identifiar aqu...\n",
      "13  ('Step', ' 3: unificación entre pólizas proven...\n",
      "14  ('Step', ' 4: Cruce con certificados para suma...\n",
      "15  ('Step', ' 4_1: Preparacion de la tabla de cer...\n",
      "16  ('LC', ': Se excluyen aquellas pólizas que fue...\n",
      "17  ('Step', ' 4_2: Join entre las pólizas de HSBC...\n",
      "18  ('LC', ': Se modifica el número de certif. par...\n",
      "19  ('Step', ' 5: Cruce con emisones para traer el...\n",
      "20  ('Step', ' 5_1: Preparacion de la tabla de emi...\n",
      "21  ('Step', ' 5_2: Se filtran los NTYP y se dejan...\n",
      "22  ('LC', ': Me lo comento Joa (esto se lo inform...\n",
      "23  ('LC', ': Son los registros con última fecha d...\n",
      "24  ('Step', ' 5_3: Join entre las polizas de HSBC...\n",
      "25  ('LC', ': Se crea un flg para identificar aque...\n",
      "26  ('LC', ': Se crea un flg para identificar aque...\n",
      "27  ('LC', ': Identificamos aquellas solicitudes p...\n",
      "28  ('Step', ' 6: Cruce con estrucutra de gestión ...\n",
      "29  ('Step', ' 7: Se corrigue el campo punto_venta...\n",
      "30  ('Step', ' 8: Unificación con tabla presupuest...\n",
      "31                       ('Step', ' 8: Final Select')\n"
     ]
    }
   ],
   "source": [
    "print(df_documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'documentation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 15\u001b[0m\n\u001b[0;32m      2\u001b[0m html_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m<!DOCTYPE html>\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m<html lang=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mes\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m    <ul>\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Agregar cada elemento de la lista como un ítem en una lista HTML\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m elemento \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdocumentation\u001b[49m:\n\u001b[0;32m     16\u001b[0m     html_template \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        <li>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00melemento\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</li>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Cerrar la etiqueta de la lista y el cuerpo del HTML\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'documentation' is not defined"
     ]
    }
   ],
   "source": [
    "# Crear una plantilla básica de HTML\n",
    "html_template = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"es\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Lista en HTML</title>\n",
    "</head>\n",
    "<body>\n",
    "    <ul>\n",
    "\"\"\"\n",
    "\n",
    "# Agregar cada elemento de la lista como un ítem en una lista HTML\n",
    "for elemento in documentation:\n",
    "    html_template += f\"        <li>{elemento}</li>\\n\"\n",
    "\n",
    "# Cerrar la etiqueta de la lista y el cuerpo del HTML\n",
    "html_template += \"\"\"\n",
    "    </ul>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Guardar el contenido HTML en un nuevo archivo\n",
    "with open('lista.html', 'w', encoding='utf-8') as file:\n",
    "    file.write(html_template)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
